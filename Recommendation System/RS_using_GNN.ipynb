{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"saurav9786/amazon-product-reviews\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8000, 4)\n",
      "Validation set shape: (1000, 4)\n",
      "Test set shape: (1000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8690</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1365811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3470</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4247</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1367193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4889</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1374451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1206</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334707200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  rating   timestamp\n",
       "0     8690           0     5.0  1365811200\n",
       "1     3470           1     5.0  1341100800\n",
       "2     4247           2     1.0  1367193600\n",
       "3     4889           2     3.0  1374451200\n",
       "4     1206           2     1.0  1334707200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "url = \"./1/ratings_Electronics (1).csv\"\n",
    "col_names = [\"user_id\", \"product_id\", \"rating\", \"timestamp\"]\n",
    "df = pd.read_csv(url, \n",
    "                  header = None,\n",
    "                 names = col_names)\n",
    "# Crop data\n",
    "df = df.head(10000)\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# Encode user IDs and item IDs\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user_id'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['product_id'] = item_encoder.fit_transform(df['product_id'])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shape of the datasets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Graph Contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 8000], edge_attr=[8000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create edge index from user-item interactions\n",
    "edge_index = torch.tensor(np.array([train_df['user_id'].values, train_df['product_id'].values]), dtype=torch.long)\n",
    "\n",
    "# Create edge attributes (ratings)\n",
    "edge_attr = torch.tensor(train_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# Create the PyTorch Geometric data object\n",
    "data = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Display the data object\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 8000], edge_attr=[8000], x=[11131, 11131])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = df['user_id'].nunique()\n",
    "num_items = df['product_id'].nunique()\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "# Create node features\n",
    "node_features = torch.eye(num_nodes)\n",
    "\n",
    "# Add node features to the data object\n",
    "data.x = node_features\n",
    "\n",
    "# Display the updated data object\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(11131, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply the final linear layer on the concatenated edge features\n",
    "        edge_pred = self.fc(torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=1))\n",
    "        return edge_pred.squeeze()\n",
    "\n",
    "# Initialize the model\n",
    "model = GCN(in_channels=node_features.size(1), hidden_channels=16, out_channels=1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1. Drawing the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcn_model_architecture.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a dummy input for visualization\n",
    "dummy_data = torch.zeros((1, node_features.size(1)))  # Adjust the size as needed\n",
    "dummy_edge_index = torch.tensor([[0], [0]], dtype=torch.long)  # Example edge index\n",
    "dummy_data_object = Data(x=dummy_data, edge_index=dummy_edge_index)\n",
    "\n",
    "# Forward pass to get the output\n",
    "output = model(dummy_data_object)\n",
    "\n",
    "# Visualize the model architecture\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.render(\"gcn_model_architecture\", format=\"png\")  # Save as PNG file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/homesweethome/anaconda3/envs/python-3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8000, 1])) that is different to the input size (torch.Size([8000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 18.598840713500977\n",
      "Epoch 2, Loss: 17.447160720825195\n",
      "Epoch 3, Loss: 15.80548095703125\n",
      "Epoch 4, Loss: 13.80807113647461\n",
      "Epoch 5, Loss: 11.646232604980469\n",
      "Epoch 6, Loss: 9.628479957580566\n",
      "Epoch 7, Loss: 8.216821670532227\n",
      "Epoch 8, Loss: 7.831818580627441\n",
      "Epoch 9, Loss: 8.222282409667969\n",
      "Epoch 10, Loss: 8.225130081176758\n",
      "Epoch 11, Loss: 7.493508815765381\n",
      "Epoch 12, Loss: 6.430135726928711\n",
      "Epoch 13, Loss: 5.502135276794434\n",
      "Epoch 14, Loss: 4.850258827209473\n",
      "Epoch 15, Loss: 4.511412620544434\n",
      "Epoch 16, Loss: 4.360482215881348\n",
      "Epoch 17, Loss: 4.254871845245361\n",
      "Epoch 18, Loss: 4.110317230224609\n",
      "Epoch 19, Loss: 3.9027109146118164\n",
      "Epoch 20, Loss: 3.6668694019317627\n",
      "Epoch 21, Loss: 3.464456081390381\n",
      "Epoch 22, Loss: 3.3498716354370117\n",
      "Epoch 23, Loss: 3.3334872722625732\n",
      "Epoch 24, Loss: 3.3537817001342773\n",
      "Epoch 25, Loss: 3.3182876110076904\n",
      "Epoch 26, Loss: 3.199431896209717\n",
      "Epoch 27, Loss: 3.043088674545288\n",
      "Epoch 28, Loss: 2.902818441390991\n",
      "Epoch 29, Loss: 2.808452606201172\n",
      "Epoch 30, Loss: 2.757836103439331\n",
      "Epoch 31, Loss: 2.730891704559326\n",
      "Epoch 32, Loss: 2.703752279281616\n",
      "Epoch 33, Loss: 2.668657064437866\n",
      "Epoch 34, Loss: 2.6426355838775635\n",
      "Epoch 35, Loss: 2.633151054382324\n",
      "Epoch 36, Loss: 2.6275484561920166\n",
      "Epoch 37, Loss: 2.607606887817383\n",
      "Epoch 38, Loss: 2.5758392810821533\n",
      "Epoch 39, Loss: 2.5463054180145264\n",
      "Epoch 40, Loss: 2.5261952877044678\n",
      "Epoch 41, Loss: 2.511146306991577\n",
      "Epoch 42, Loss: 2.4943509101867676\n",
      "Epoch 43, Loss: 2.474905252456665\n",
      "Epoch 44, Loss: 2.457489013671875\n",
      "Epoch 45, Loss: 2.446544885635376\n",
      "Epoch 46, Loss: 2.4410479068756104\n",
      "Epoch 47, Loss: 2.4351515769958496\n",
      "Epoch 48, Loss: 2.425278663635254\n",
      "Epoch 49, Loss: 2.4135138988494873\n",
      "Epoch 50, Loss: 2.4037375450134277\n",
      "Epoch 51, Loss: 2.3967554569244385\n",
      "Epoch 52, Loss: 2.3899788856506348\n",
      "Epoch 53, Loss: 2.3811757564544678\n",
      "Epoch 54, Loss: 2.3708159923553467\n",
      "Epoch 55, Loss: 2.361161470413208\n",
      "Epoch 56, Loss: 2.3536806106567383\n",
      "Epoch 57, Loss: 2.3475046157836914\n",
      "Epoch 58, Loss: 2.3407554626464844\n",
      "Epoch 59, Loss: 2.3329479694366455\n",
      "Epoch 60, Loss: 2.3253026008605957\n",
      "Epoch 61, Loss: 2.3189504146575928\n",
      "Epoch 62, Loss: 2.3135557174682617\n",
      "Epoch 63, Loss: 2.3079538345336914\n",
      "Epoch 64, Loss: 2.301693916320801\n",
      "Epoch 65, Loss: 2.295466661453247\n",
      "Epoch 66, Loss: 2.2901434898376465\n",
      "Epoch 67, Loss: 2.285766363143921\n",
      "Epoch 68, Loss: 2.281374931335449\n",
      "Epoch 69, Loss: 2.276542901992798\n",
      "Epoch 70, Loss: 2.271740674972534\n",
      "Epoch 71, Loss: 2.267550230026245\n",
      "Epoch 72, Loss: 2.263883113861084\n",
      "Epoch 73, Loss: 2.2602274417877197\n",
      "Epoch 74, Loss: 2.256355047225952\n",
      "Epoch 75, Loss: 2.2525837421417236\n",
      "Epoch 76, Loss: 2.2492480278015137\n",
      "Epoch 77, Loss: 2.246211051940918\n",
      "Epoch 78, Loss: 2.2431490421295166\n",
      "Epoch 79, Loss: 2.2400245666503906\n",
      "Epoch 80, Loss: 2.237088441848755\n",
      "Epoch 81, Loss: 2.234485387802124\n",
      "Epoch 82, Loss: 2.232032060623169\n",
      "Epoch 83, Loss: 2.2295289039611816\n",
      "Epoch 84, Loss: 2.2270421981811523\n",
      "Epoch 85, Loss: 2.224738597869873\n",
      "Epoch 86, Loss: 2.2226035594940186\n",
      "Epoch 87, Loss: 2.2204742431640625\n",
      "Epoch 88, Loss: 2.2183029651641846\n",
      "Epoch 89, Loss: 2.216205596923828\n",
      "Epoch 90, Loss: 2.2142560482025146\n",
      "Epoch 91, Loss: 2.212378740310669\n",
      "Epoch 92, Loss: 2.2104952335357666\n",
      "Epoch 93, Loss: 2.208655834197998\n",
      "Epoch 94, Loss: 2.206939935684204\n",
      "Epoch 95, Loss: 2.2053234577178955\n",
      "Epoch 96, Loss: 2.2037317752838135\n",
      "Epoch 97, Loss: 2.202172040939331\n",
      "Epoch 98, Loss: 2.200701951980591\n",
      "Epoch 99, Loss: 2.1993205547332764\n",
      "Epoch 100, Loss: 2.197974681854248\n",
      "Epoch 101, Loss: 2.1966545581817627\n",
      "Epoch 102, Loss: 2.195399761199951\n",
      "Epoch 103, Loss: 2.194218635559082\n",
      "Epoch 104, Loss: 2.19307541847229\n",
      "Epoch 105, Loss: 2.191957950592041\n",
      "Epoch 106, Loss: 2.190894365310669\n",
      "Epoch 107, Loss: 2.189892530441284\n",
      "Epoch 108, Loss: 2.1889278888702393\n",
      "Epoch 109, Loss: 2.1879920959472656\n",
      "Epoch 110, Loss: 2.1871042251586914\n",
      "Epoch 111, Loss: 2.1862690448760986\n",
      "Epoch 112, Loss: 2.185467481613159\n",
      "Epoch 113, Loss: 2.18469500541687\n",
      "Epoch 114, Loss: 2.183964490890503\n",
      "Epoch 115, Loss: 2.1832754611968994\n",
      "Epoch 116, Loss: 2.182614803314209\n",
      "Epoch 117, Loss: 2.1819794178009033\n",
      "Epoch 118, Loss: 2.181380033493042\n",
      "Epoch 119, Loss: 2.1808130741119385\n",
      "Epoch 120, Loss: 2.1802690029144287\n",
      "Epoch 121, Loss: 2.1797502040863037\n",
      "Epoch 122, Loss: 2.1792616844177246\n",
      "Epoch 123, Loss: 2.178800106048584\n",
      "Epoch 124, Loss: 2.178359031677246\n",
      "Epoch 125, Loss: 2.1779420375823975\n",
      "Epoch 126, Loss: 2.177550792694092\n",
      "Epoch 127, Loss: 2.177180528640747\n",
      "Epoch 128, Loss: 2.176828384399414\n",
      "Epoch 129, Loss: 2.176497459411621\n",
      "Epoch 130, Loss: 2.1761865615844727\n",
      "Epoch 131, Loss: 2.1758921146392822\n",
      "Epoch 132, Loss: 2.1756129264831543\n",
      "Epoch 133, Loss: 2.17535138130188\n",
      "Epoch 134, Loss: 2.175105571746826\n",
      "Epoch 135, Loss: 2.174872636795044\n",
      "Epoch 136, Loss: 2.174654245376587\n",
      "Epoch 137, Loss: 2.1744496822357178\n",
      "Epoch 138, Loss: 2.174257278442383\n",
      "Epoch 139, Loss: 2.1740760803222656\n",
      "Epoch 140, Loss: 2.1739063262939453\n",
      "Epoch 141, Loss: 2.1737477779388428\n",
      "Epoch 142, Loss: 2.173598289489746\n",
      "Epoch 143, Loss: 2.1734580993652344\n",
      "Epoch 144, Loss: 2.1733272075653076\n",
      "Epoch 145, Loss: 2.173203945159912\n",
      "Epoch 146, Loss: 2.173088788986206\n",
      "Epoch 147, Loss: 2.172980785369873\n",
      "Epoch 148, Loss: 2.172879457473755\n",
      "Epoch 149, Loss: 2.1727843284606934\n",
      "Epoch 150, Loss: 2.1726949214935303\n",
      "Epoch 151, Loss: 2.172611951828003\n",
      "Epoch 152, Loss: 2.1725335121154785\n",
      "Epoch 153, Loss: 2.172459840774536\n",
      "Epoch 154, Loss: 2.172390937805176\n",
      "Epoch 155, Loss: 2.17232608795166\n",
      "Epoch 156, Loss: 2.172264814376831\n",
      "Epoch 157, Loss: 2.1722075939178467\n",
      "Epoch 158, Loss: 2.1721534729003906\n",
      "Epoch 159, Loss: 2.172102451324463\n",
      "Epoch 160, Loss: 2.1720545291900635\n",
      "Epoch 161, Loss: 2.172008991241455\n",
      "Epoch 162, Loss: 2.171966314315796\n",
      "Epoch 163, Loss: 2.1719255447387695\n",
      "Epoch 164, Loss: 2.171886920928955\n",
      "Epoch 165, Loss: 2.1718504428863525\n",
      "Epoch 166, Loss: 2.171816110610962\n",
      "Epoch 167, Loss: 2.171782970428467\n",
      "Epoch 168, Loss: 2.1717512607574463\n",
      "Epoch 169, Loss: 2.1717212200164795\n",
      "Epoch 170, Loss: 2.1716926097869873\n",
      "Epoch 171, Loss: 2.1716649532318115\n",
      "Epoch 172, Loss: 2.1716384887695312\n",
      "Epoch 173, Loss: 2.1716134548187256\n",
      "Epoch 174, Loss: 2.171588897705078\n",
      "Epoch 175, Loss: 2.1715660095214844\n",
      "Epoch 176, Loss: 2.171543598175049\n",
      "Epoch 177, Loss: 2.1715219020843506\n",
      "Epoch 178, Loss: 2.1715009212493896\n",
      "Epoch 179, Loss: 2.171480655670166\n",
      "Epoch 180, Loss: 2.171461343765259\n",
      "Epoch 181, Loss: 2.1714425086975098\n",
      "Epoch 182, Loss: 2.171424150466919\n",
      "Epoch 183, Loss: 2.1714065074920654\n",
      "Epoch 184, Loss: 2.171389579772949\n",
      "Epoch 185, Loss: 2.171372413635254\n",
      "Epoch 186, Loss: 2.171356439590454\n",
      "Epoch 187, Loss: 2.1713404655456543\n",
      "Epoch 188, Loss: 2.171325206756592\n",
      "Epoch 189, Loss: 2.1713101863861084\n",
      "Epoch 190, Loss: 2.171295404434204\n",
      "Epoch 191, Loss: 2.171281576156616\n",
      "Epoch 192, Loss: 2.171267509460449\n",
      "Epoch 193, Loss: 2.1712539196014404\n",
      "Epoch 194, Loss: 2.17124080657959\n",
      "Epoch 195, Loss: 2.1712276935577393\n",
      "Epoch 196, Loss: 2.171215295791626\n",
      "Epoch 197, Loss: 2.1712028980255127\n",
      "Epoch 198, Loss: 2.1711909770965576\n",
      "Epoch 199, Loss: 2.1711790561676025\n",
      "Epoch 200, Loss: 2.1711676120758057\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data loader\n",
    "train_loader = DataLoader([data], batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.edge_attr.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 1.4742927666112078, Validation MAE: 1.275151252746582\n",
      "Test RMSE: 1.4363036775310978, Test MAE: 1.2575424909591675\n"
     ]
    }
   ],
   "source": [
    "# Convert validation and test data to PyTorch Geometric format\n",
    "val_edge_index = torch.tensor([val_df['user_id'].values, val_df['product_id'].values], dtype=torch.long)\n",
    "val_edge_attr = torch.tensor(val_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "test_edge_index = torch.tensor([test_df['user_id'].values, test_df['product_id'].values], dtype=torch.long)\n",
    "test_edge_attr = torch.tensor(test_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# Create data objects for validation and test sets\n",
    "val_data = Data(edge_index=val_edge_index, edge_attr=val_edge_attr, x=node_features)\n",
    "test_data = Data(edge_index=test_edge_index, edge_attr=test_edge_attr, x=node_features)\n",
    "\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "val_mse = mean_squared_error(val_edge_attr.numpy(), val_out.numpy())\n",
    "val_rmse = np.sqrt(val_mse)  # Manually calculate RMSE\n",
    "val_mae = mean_absolute_error(val_edge_attr.numpy(), val_out.numpy())\n",
    "\n",
    "test_mse = mean_squared_error(test_edge_attr.numpy(), test_out.numpy())\n",
    "test_rmse = np.sqrt(test_mse)  # Manually calculate RMSE\n",
    "test_mae = mean_absolute_error(test_edge_attr.numpy(), test_out.numpy())\n",
    "\n",
    "print(f'Validation RMSE: {val_rmse}, Validation MAE: {val_mae}')\n",
    "print(f'Test RMSE: {test_rmse}, Test MAE: {test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[11131, 11131], edge_index=[2, 1000], edge_attr=[1000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
